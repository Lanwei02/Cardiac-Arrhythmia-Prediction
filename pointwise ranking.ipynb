{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Retrieving basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "#From skleanr preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#For modelling\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#For model selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Dimension Reduction\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardio=pd.read_csv(\"cardiac_arrhythmia.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   270   271  272  273  \\\n",
       "0   75    0  190   80   91  193  371  174  121  -16 ...   0.0   9.0 -0.9  0.0   \n",
       "1   56    1  165   64   81  174  401  149   39   25 ...   0.0   8.5  0.0  0.0   \n",
       "2   54    0  172   95  138  163  386  185  102   96 ...   0.0   9.5 -2.4  0.0   \n",
       "3   55    0  175   94  100  202  380  179  143   28 ...   0.0  12.2 -2.2  0.0   \n",
       "4   75    0  190   80   88  181  360  177  103  -16 ...   0.0  13.1 -3.6  0.0   \n",
       "\n",
       "  274  275  276   277   278  279  \n",
       "0   0  0.9  2.9  23.3  49.4    8  \n",
       "1   0  0.2  2.1  20.4  38.8    6  \n",
       "2   0  0.3  3.4  12.3  49.0   10  \n",
       "3   0  0.4  2.6  34.6  61.6    1  \n",
       "4   0 -0.1  3.9  25.4  62.8    7  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([10, 11, 12, 13, 14], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#Identifying str columns and convert them to int\n",
    "cardio_object=cardio.loc[:,cardio.dtypes==\"object\"]\n",
    "print(cardio_object.columns)\n",
    "for i in list(cardio_object.columns):\n",
    "    cardio[i] = pd.to_numeric(cardio[i], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cloumns with more than 95% null values\n",
    "cardio=cardio.loc[:,cardio.notnull().sum()>len(cardio)*0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill the rest of null values with mean\n",
    "cardio=cardio.fillna(cardio.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     245\n",
       "10     50\n",
       "2      44\n",
       "6      25\n",
       "16     22\n",
       "4      15\n",
       "3      15\n",
       "5      13\n",
       "9       9\n",
       "15      5\n",
       "14      4\n",
       "7       3\n",
       "8       2\n",
       "Name: 279, dtype: int64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardio.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = cardio.iloc[:,:-1]\n",
    "y = cardio.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate calss: 7, 8, 9, 14, 15 since the number of the five classes are too small\n",
    "y = pd.Series([100 if i == 7 or i == 8 or i == 9 or i == 14 or i == 15 else i for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.25, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scaling the dataframe\n",
    "minmax=MinMaxScaler()\n",
    "X_train_mms=minmax.fit_transform(X_train)\n",
    "X_test_mms=minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      184\n",
      "10      38\n",
      "2       33\n",
      "6       19\n",
      "100     17\n",
      "16      16\n",
      "4       11\n",
      "3       11\n",
      "5       10\n",
      "dtype: int64\n",
      "1      61\n",
      "10     12\n",
      "2      11\n",
      "100     6\n",
      "16      6\n",
      "6       6\n",
      "4       4\n",
      "3       4\n",
      "5       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: {'max_depth': 15, 'n_estimators': 30}\n",
      "Best cross-validation Accuracy: 0.7286\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Setting the parameters\n",
    "aux_randomforest=RandomForestClassifier()\n",
    "randomforestparam = {\"n_estimators\":[6, 10, 20, 25, 30, 50],\n",
    "     \"max_depth\":[5,10,15,20, None]}\n",
    "grid_randomforest=GridSearchCV(aux_randomforest, randomforestparam, cv=5)\n",
    "\n",
    "#Fitting\n",
    "grid_randomforest.fit(X_train_mms, y_train)\n",
    "\n",
    "#Print reports\n",
    "print(\"Best K: {}\".format(grid_randomforest.best_params_))\n",
    "print(\"Best cross-validation Accuracy: {:.4f}\".format(grid_randomforest.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_randomforest.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train): 0.9941\n",
      "Accuracy(Test): 0.7080\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.92      0.84        61\n",
      "          2       0.45      0.45      0.45        11\n",
      "          3       0.60      0.75      0.67         4\n",
      "          4       0.67      0.50      0.57         4\n",
      "          5       0.00      0.00      0.00         3\n",
      "          6       0.75      0.50      0.60         6\n",
      "         10       0.64      0.75      0.69        12\n",
      "         16       0.00      0.00      0.00         6\n",
      "        100       1.00      0.33      0.50         6\n",
      "\n",
      "avg / total       0.66      0.71      0.67       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randomforest=RandomForestClassifier(max_depth=15, n_estimators=30)\n",
    "randomforest.fit(X_train_mms, y_train)\n",
    "\n",
    "\n",
    "yrandomforest_test_predict = randomforest.predict(X_test_mms)\n",
    "\n",
    "\n",
    "print('Accuracy (Train): {:.4f}'.format(randomforest.score(X_train_mms, y_train)))\n",
    "print('Accuracy(Test): {:.4f}'.format(randomforest.score(X_test_mms, y_test)))\n",
    "print(classification_report(y_test, yrandomforest_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Classes Pointwise Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number:  100\n",
      "Best C: {'C': 0.001}\n",
      "Best cross-validation auc_roc: 0.7142\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  6\n",
      "Best C: {'C': 0.1}\n",
      "Best cross-validation auc_roc: 0.9207\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  10\n",
      "Best C: {'C': 0.001}\n",
      "Best cross-validation auc_roc: 0.9644\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  1\n",
      "Best C: {'C': 0.001}\n",
      "Best cross-validation auc_roc: 0.7762\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  3\n",
      "Best C: {'C': 0.001}\n",
      "Best cross-validation auc_roc: 0.9893\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  16\n",
      "Best C: {'C': 0.001}\n",
      "Best cross-validation auc_roc: 0.4662\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  2\n",
      "Best C: {'C': 0.001}\n",
      "Best cross-validation auc_roc: 0.7906\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  4\n",
      "Best C: {'C': 0.001}\n",
      "Best cross-validation auc_roc: 0.9804\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  5\n",
      "Best C: {'C': 0.5}\n",
      "Best cross-validation auc_roc: 0.9091\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"C\":[0.001, 0.01, 0.1,0.5, 1,5]}\n",
    "probability_lg = pd.DataFrame()\n",
    "for n in y.unique():\n",
    "    print('Class number: ', n)\n",
    "    # create y for the class\n",
    "    y_train_loop = pd.Series([1 if i == n else 0 for i in y_train])\n",
    "    y_test_loop = pd.Series([1 if i == n else 0 for i in y_test])\n",
    "    # tuning parameters\n",
    "    grid_logit=GridSearchCV(LogisticRegression(), parameters , scoring = 'roc_auc', cv=3)\n",
    "    grid_logit.fit(X_train, y_train_loop)\n",
    "    print(\"Best C: {}\".format(grid_logit.best_params_))\n",
    "    print(\"Best cross-validation auc_roc: {:.4f}\".format(grid_logit.best_score_))\n",
    "    print('Best estimator:\\n{}'.format(grid_logit.best_estimator_))\n",
    "    best_model = grid_logit.best_estimator_\n",
    "    best_model.fit(X_train, y_train_loop)\n",
    "    # probability \n",
    "    probability_lg[\"Topic #%d \" % n] = best_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_lg['ranking'] = probability_lg.idxmax(axis=1)\n",
    "probability_lg['true'] = list(y_test)\n",
    "probability_lg['ranking_2'] = probability_lg['ranking'].map(lambda x:pd.to_numeric(x.split('#')[-1].rstrip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.80      0.77        61\n",
      "          2       0.86      0.55      0.67        11\n",
      "          3       0.80      1.00      0.89         4\n",
      "          4       0.75      0.75      0.75         4\n",
      "          5       0.33      0.67      0.44         3\n",
      "          6       0.25      0.33      0.29         6\n",
      "         10       0.64      0.58      0.61        12\n",
      "         16       0.00      0.00      0.00         6\n",
      "        100       0.67      0.33      0.44         6\n",
      "\n",
      "avg / total       0.66      0.66      0.65       113\n",
      "\n",
      "Accuracy: 0.6637\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(probability_lg['true'], probability_lg['ranking_2']))\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(probability_lg['true'], probability_lg['ranking_2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.74      0.80        61\n",
      "          2       0.50      0.45      0.48        11\n",
      "          3       0.40      0.50      0.44         4\n",
      "          4       0.16      0.75      0.26         4\n",
      "          5       0.50      0.67      0.57         3\n",
      "          6       0.62      0.83      0.71         6\n",
      "         10       0.53      0.67      0.59        12\n",
      "         16       0.00      0.00      0.00         6\n",
      "        100       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.64      0.62      0.62       113\n",
      "\n",
      "Accuracy: 0.7080\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, ytree_test_predict))\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, yrandomforest_test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number:  100\n",
      "Best C: {'max_depth': None, 'n_estimators': 50}\n",
      "Best cross-validation auc_roc: 0.8147\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  6\n",
      "Best C: {'max_depth': None, 'n_estimators': 10}\n",
      "Best cross-validation auc_roc: 0.9599\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  10\n",
      "Best C: {'max_depth': 5, 'n_estimators': 20}\n",
      "Best cross-validation auc_roc: 0.9686\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  1\n",
      "Best C: {'max_depth': 20, 'n_estimators': 20}\n",
      "Best cross-validation auc_roc: 0.8657\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  3\n",
      "Best C: {'max_depth': None, 'n_estimators': 20}\n",
      "Best cross-validation auc_roc: 0.9946\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  16\n",
      "Best C: {'max_depth': 20, 'n_estimators': 10}\n",
      "Best cross-validation auc_roc: 0.6576\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  2\n",
      "Best C: {'max_depth': 10, 'n_estimators': 25}\n",
      "Best cross-validation auc_roc: 0.9360\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  4\n",
      "Best C: {'max_depth': 15, 'n_estimators': 30}\n",
      "Best cross-validation auc_roc: 0.9730\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  5\n",
      "Best C: {'max_depth': None, 'n_estimators': 10}\n",
      "Best cross-validation auc_roc: 0.8858\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "randomforestparam = {\"n_estimators\":[6, 10, 20, 25, 30, 50],\n",
    "     \"max_depth\":[5,10,15,20, None]}\n",
    "probability = pd.DataFrame()\n",
    "for n in y.unique():\n",
    "    print('Class number: ', n)\n",
    "    # create y for the class\n",
    "    y_train_loop = pd.Series([1 if i == n else 0 for i in y_train])\n",
    "    y_test_loop = pd.Series([1 if i == n else 0 for i in y_test])\n",
    "    # tuning parameters\n",
    "    grid_logit=GridSearchCV(RandomForestClassifier(), randomforestparam , scoring = 'roc_auc', cv=3)\n",
    "    grid_logit.fit(X_train_mms, y_train_loop)\n",
    "    print(\"Best C: {}\".format(grid_logit.best_params_))\n",
    "    print(\"Best cross-validation auc_roc: {:.4f}\".format(grid_logit.best_score_))\n",
    "    print('Best estimator:\\n{}'.format(grid_logit.best_estimator_))\n",
    "    best_model = grid_logit.best_estimator_\n",
    "    best_model.fit(X_train_mms, y_train_loop)\n",
    "    # probability \n",
    "    probability[\"Topic #%d \" % n] = best_model.predict_proba(X_test_mms)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability['ranking'] = probability.idxmax(axis=1)\n",
    "probability['true'] = list(y_test)\n",
    "probability['ranking_2'] = probability['ranking'].map(lambda x:pd.to_numeric(x.split('#')[-1].rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.95      0.81        61\n",
      "          2       0.50      0.36      0.42        11\n",
      "          3       0.75      0.75      0.75         4\n",
      "          4       0.67      0.50      0.57         4\n",
      "          5       1.00      0.33      0.50         3\n",
      "          6       0.50      0.17      0.25         6\n",
      "         10       0.71      0.42      0.53        12\n",
      "         16       0.00      0.00      0.00         6\n",
      "        100       1.00      0.50      0.67         6\n",
      "\n",
      "avg / total       0.66      0.68      0.64       113\n",
      "\n",
      "Accuracy: 0.6814\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(probability['true'], probability['ranking_2']))\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(probability['true'], probability['ranking_2'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_number = pd.DataFrame(columns=['Principle Components', 'Explained Variance', 'Multi(Test)'])\n",
    "index=0\n",
    "for i in list(range(2, 278))[::5]:\n",
    "    #PCA  X_train, y_train\n",
    "    pca=PCA(n_components=i)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca=pca.transform(X_train_mms)\n",
    "    X_test_pca=pca.transform(X_test_mms)\n",
    "    variance=pca.explained_variance_ratio_.sum()\n",
    "        \n",
    "    #multi class KNN\n",
    "    knn=KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train_pca, y_train)\n",
    "    prediction=knn.predict(X_test_pca)\n",
    "    multi=accuracy_score(y_test, prediction)\n",
    "    \n",
    "    pca_number.loc[index]=[i,variance,multi]\n",
    "    index=index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a19f14a58>"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAHVCAYAAAAXVW0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAANSd/x8uStrzVaL0SQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a19eb7b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16,8))\n",
    "ax[0].plot('Principle Components', 'Multi(Test)','*-',data=pca_number)\n",
    "ax[0].grid(True)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot('Principle Components', 'Explained Variance','.-',data=pca_number)\n",
    "ax[1].grid(True)\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of preserving variance is :82.04 %\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(n_components=37)\n",
    "pca.fit(Xtrain_mms)\n",
    "Xtrain_pca=pca.transform(Xtrain_mms)\n",
    "Xtest_pca=pca.transform(Xtest_mms)\n",
    "print('The percent of preserving variance is :{:.2f} %'.format(pca.explained_variance_ratio_.sum()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: {'C': 1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "Best cross-validation R square: 0.7139\n",
      "Best estimator:\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#Setting the parameters\n",
    "aux_linearSVC_pca=SVC()\n",
    "linearSVCparam_pca={\"kernel\":[\"linear\"],\n",
    "               \"C\":[1,10,100,1000],\n",
    "               \"gamma\":[0.01, 0.1, 0.5, 1]}\n",
    "grid_linearSVC_pca=GridSearchCV(aux_linearSVC_pca, linearSVCparam_pca, cv=5)\n",
    "\n",
    "#Fitting\n",
    "grid_linearSVC_pca.fit(Xtrain_pca, y_train)\n",
    "\n",
    "#Print reports\n",
    "print(\"Best K: {}\".format(grid_linearSVC_pca.best_params_))\n",
    "print(\"Best cross-validation R square: {:.4f}\".format(grid_linearSVC_pca.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_linearSVC_pca.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (training): 0.8230\n",
      "Accuracy (test): 0.6814\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.92      0.79        61\n",
      "          2       0.62      0.45      0.53        11\n",
      "          3       0.80      1.00      0.89         4\n",
      "          4       0.50      0.75      0.60         4\n",
      "          5       1.00      0.33      0.50         3\n",
      "          6       0.00      0.00      0.00         6\n",
      "         10       0.71      0.42      0.53        12\n",
      "         16       0.50      0.17      0.25         6\n",
      "        100       0.67      0.33      0.44         6\n",
      "\n",
      "avg / total       0.65      0.68      0.64       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linearSVCmodel_pca=SVC(C=1, gamma=0.01, kernel=\"linear\")\n",
    "linearSVCmodel_pca.fit(Xtrain_pca, y_train)\n",
    "\n",
    "ylinearSVC_test_predict_pca=linearSVCmodel_pca.predict(Xtest_pca)\n",
    "\n",
    "print('Accuracy (training): {:.4f}'.format(linearSVCmodel_pca.score(Xtrain_pca, y_train)))\n",
    "print('Accuracy (test): {:.4f}'.format(linearSVCmodel_pca.score(Xtest_pca, y_test)))\n",
    "\n",
    "print(classification_report(y_test, ylinearSVC_test_predict_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number:  100\n",
      "Best C: {'max_depth': 20, 'n_estimators': 30}\n",
      "Best cross-validation auc_roc: 0.8026\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  6\n",
      "Best C: {'max_depth': 5, 'n_estimators': 25}\n",
      "Best cross-validation auc_roc: 0.6749\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  10\n",
      "Best C: {'max_depth': 15, 'n_estimators': 20}\n",
      "Best cross-validation auc_roc: 0.8612\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  1\n",
      "Best C: {'max_depth': 15, 'n_estimators': 50}\n",
      "Best cross-validation auc_roc: 0.7850\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  3\n",
      "Best C: {'max_depth': None, 'n_estimators': 25}\n",
      "Best cross-validation auc_roc: 0.9904\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  16\n",
      "Best C: {'max_depth': 15, 'n_estimators': 20}\n",
      "Best cross-validation auc_roc: 0.6753\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  2\n",
      "Best C: {'max_depth': 10, 'n_estimators': 20}\n",
      "Best cross-validation auc_roc: 0.8084\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  4\n",
      "Best C: {'max_depth': 5, 'n_estimators': 50}\n",
      "Best cross-validation auc_roc: 0.9493\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Class number:  5\n",
      "Best C: {'max_depth': 15, 'n_estimators': 50}\n",
      "Best cross-validation auc_roc: 0.7153\n",
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "randomforestparam = {\"n_estimators\":[6, 10, 20, 25, 30, 50],\n",
    "     \"max_depth\":[5,10,15,20, None]}\n",
    "probability_PCA = pd.DataFrame()\n",
    "for n in y.unique():\n",
    "    print('Class number: ', n)\n",
    "    # create y for the class\n",
    "    y_train_loop = pd.Series([1 if i == n else 0 for i in y_train])\n",
    "    y_test_loop = pd.Series([1 if i == n else 0 for i in y_test])\n",
    "    # tuning parameters\n",
    "    grid_logit=GridSearchCV(RandomForestClassifier(), randomforestparam , scoring = 'roc_auc', cv=3)\n",
    "    grid_logit.fit(Xtrain_pca, y_train_loop)\n",
    "    print(\"Best C: {}\".format(grid_logit.best_params_))\n",
    "    print(\"Best cross-validation auc_roc: {:.4f}\".format(grid_logit.best_score_))\n",
    "    print('Best estimator:\\n{}'.format(grid_logit.best_estimator_))\n",
    "    best_model = grid_logit.best_estimator_\n",
    "    best_model.fit(Xtrain_pca, y_train_loop)\n",
    "    # probability \n",
    "    probability_PCA[\"Topic #%d \" % n] = best_model.predict_proba(Xtest_pca)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probability_PCA['ranking'] = probability_PCA.idxmax(axis=1)\n",
    "probability_PCA['true'] = list(y_test)\n",
    "probability_PCA['ranking_2'] = probability_PCA['ranking'].map(lambda x:pd.to_numeric(x.split('#')[-1].rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.93      0.79        61\n",
      "          2       0.38      0.27      0.32        11\n",
      "          3       0.67      1.00      0.80         4\n",
      "          4       1.00      0.75      0.86         4\n",
      "          5       0.50      0.33      0.40         3\n",
      "          6       0.00      0.00      0.00         6\n",
      "         10       0.71      0.42      0.53        12\n",
      "         16       0.00      0.00      0.00         6\n",
      "        100       0.75      0.50      0.60         6\n",
      "\n",
      "avg / total       0.60      0.67      0.62       113\n",
      "\n",
      "Accuracy: 0.6726\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(probability['true'], probability['ranking_2']))\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(probability['true'], probability['ranking_2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class number:  100\n",
      "Best C: {'C': 0.1}\n",
      "Best cross-validation auc_roc: 0.7067\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  6\n",
      "Best C: {'C': 5}\n",
      "Best cross-validation auc_roc: 0.7471\n",
      "Best estimator:\n",
      "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  10\n",
      "Best C: {'C': 0.5}\n",
      "Best cross-validation auc_roc: 0.9446\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  1\n",
      "Best C: {'C': 1}\n",
      "Best cross-validation auc_roc: 0.8252\n",
      "Best estimator:\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  3\n",
      "Best C: {'C': 1}\n",
      "Best cross-validation auc_roc: 0.9969\n",
      "Best estimator:\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  16\n",
      "Best C: {'C': 0.01}\n",
      "Best cross-validation auc_roc: 0.4829\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  2\n",
      "Best C: {'C': 0.5}\n",
      "Best cross-validation auc_roc: 0.8529\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  4\n",
      "Best C: {'C': 1}\n",
      "Best cross-validation auc_roc: 0.9728\n",
      "Best estimator:\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Class number:  5\n",
      "Best C: {'C': 1}\n",
      "Best cross-validation auc_roc: 0.7690\n",
      "Best estimator:\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"C\":[0.001, 0.01, 0.1,0.5, 1,5]}\n",
    "probability_lg = pd.DataFrame()\n",
    "for n in y.unique():\n",
    "    print('Class number: ', n)\n",
    "    # create y for the class\n",
    "    y_train_loop = pd.Series([1 if i == n else 0 for i in y_train])\n",
    "    y_test_loop = pd.Series([1 if i == n else 0 for i in y_test])\n",
    "    # tuning parameters\n",
    "    grid_logit=GridSearchCV(LogisticRegression(), parameters , scoring = 'roc_auc', cv=3)\n",
    "    grid_logit.fit(Xtrain_pca, y_train_loop)\n",
    "    print(\"Best C: {}\".format(grid_logit.best_params_))\n",
    "    print(\"Best cross-validation auc_roc: {:.4f}\".format(grid_logit.best_score_))\n",
    "    print('Best estimator:\\n{}'.format(grid_logit.best_estimator_))\n",
    "    best_model = grid_logit.best_estimator_\n",
    "    best_model.fit(Xtrain_pca, y_train_loop)\n",
    "    # probability \n",
    "    probability_lg[\"Topic #%d \" % n] = best_model.predict_proba(Xtest_pca)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probability_lg['ranking'] = probability_lg.idxmax(axis=1)\n",
    "probability_lg['true'] = list(y_test)\n",
    "probability_lg['ranking_2'] = probability_lg['ranking'].map(lambda x:pd.to_numeric(x.split('#')[-1].rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.93      0.81        61\n",
      "          2       0.33      0.09      0.14        11\n",
      "          3       0.80      1.00      0.89         4\n",
      "          4       0.75      0.75      0.75         4\n",
      "          5       1.00      0.33      0.50         3\n",
      "          6       0.50      0.17      0.25         6\n",
      "         10       0.75      0.50      0.60        12\n",
      "         16       0.22      0.33      0.27         6\n",
      "        100       1.00      0.17      0.29         6\n",
      "\n",
      "avg / total       0.67      0.67      0.63       113\n",
      "\n",
      "Accuracy: 0.6726\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(probability_lg['true'], probability_lg['ranking_2']))\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_score(probability_lg['true'], probability_lg['ranking_2'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
